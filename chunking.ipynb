{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silero_vad import load_silero_vad, read_audio, get_speech_timestamps\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "import math\n",
    "from io import BytesIO\n",
    "from typing import IO, List\n",
    "\n",
    "\n",
    "def _split_audio(audio_file: IO[bytes], vad_model, sampling_rate, audio_id) -> List:\n",
    "        \"\"\"\n",
    "        This is a helper function that takes an audio file and splits it into timestamps based on VAD\n",
    "\n",
    "        Parameters:\n",
    "            - audio_file (IO[bytes]) -> Audio file you want to split timestamps of\n",
    "            - vad_model (silero-vad) -> Voice Activity Detection model to analyze the audio.\n",
    "\n",
    "        Returns:\n",
    "            - audio_segments (List) -> List of audio segments (as BytesIO buffers). \n",
    "\n",
    "        TODO: \n",
    "        1. You can try to ceil or floor the timestamps to nearest integer but there could be a problem in recognizing audio if it merges with some random sound or previous syllable. \n",
    "        2. Change from mono to stereo if stereo sound is provided\n",
    "        3. Try changing the export format to mp3 and observe the results\n",
    "        \"\"\"\n",
    "\n",
    "        def split_timestamps(timestamps):\n",
    "            result = []\n",
    "\n",
    "            def find_largest_gap(chunk):\n",
    "                \"\"\"Find the index of the largest gap between consecutive timestamps.\"\"\"\n",
    "                max_gap = 0\n",
    "                split_index = None\n",
    "\n",
    "                for i in range(1, len(chunk)):\n",
    "                    gap = chunk[i]['start'] - chunk[i - 1]['end']\n",
    "                    if gap > max_gap:\n",
    "                        max_gap = gap\n",
    "                        split_index = i\n",
    "\n",
    "                return max_gap, split_index\n",
    "\n",
    "            def process_chunk(chunk):\n",
    "                \"\"\"Process a single chunk and split it if its duration is > 29 seconds.\"\"\"\n",
    "                # Base condition: If chunk has one or fewer timestamps, add it directly\n",
    "                if len(chunk) <= 1:\n",
    "                    result.append(chunk)\n",
    "                    return\n",
    "\n",
    "                # Check duration of the chunk\n",
    "                duration = chunk[-1]['end'] - chunk[0]['start']\n",
    "                if duration <= 29:\n",
    "                    result.append(chunk)  # If duration is <= 29, keep the chunk as is\n",
    "                    return\n",
    "\n",
    "                # Find the largest gap and split at that point\n",
    "                max_gap, split_index = find_largest_gap(chunk)\n",
    "\n",
    "                # If no valid split point is found, add the chunk as is\n",
    "                if max_gap <= 0 or split_index is None:\n",
    "                    result.append(chunk)\n",
    "                    return\n",
    "\n",
    "                # Split the chunk into two at the split_index\n",
    "                left_chunk = chunk[:split_index]\n",
    "                right_chunk = chunk[split_index:]\n",
    "\n",
    "                # Process each sub-chunk recursively\n",
    "                process_chunk(left_chunk)\n",
    "                process_chunk(right_chunk)\n",
    "\n",
    "            # Start processing the chunks\n",
    "            process_chunk(timestamps)\n",
    "\n",
    "            return result\n",
    "\n",
    "        # 1. Read audio and prepare it for processing\n",
    "        audio_bytes = audio_file.getvalue()\n",
    "\n",
    "        # 2. Convert the audio into BytesIO object\n",
    "        audio = BytesIO(audio_bytes)\n",
    "\n",
    "        # 3. Read audio with it's sampling rate\n",
    "        wav = read_audio(audio, sampling_rate=sampling_rate)\n",
    "\n",
    "        # 4. Get speech timestamps from the vad model \n",
    "        speech_timestamps = get_speech_timestamps(\n",
    "            wav, \n",
    "            vad_model, \n",
    "            sampling_rate=sampling_rate, \n",
    "            return_seconds=True\n",
    "        )\n",
    "     \n",
    "        # 5. Extract processed timestamps\n",
    "        processed_timestamps = split_timestamps(speech_timestamps)\n",
    "\n",
    "        # TODO: You can try to ceil or floor the timestamps to nearest integer but there could be a problem in recognizing audio if it merges with some random sound or previous syllable. \n",
    "        cleaned_processed_timestamps = []\n",
    "        for timestamps in processed_timestamps:\n",
    "            cleaned_processed_timestamps.append(\n",
    "                {\n",
    "                    \"start\": float(timestamps[0]['start']), \n",
    "                    \"end\": float(timestamps[-1]['end'])\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        # 6. Cleaning processed timestamps\n",
    "        cleaned_processed_timestamps_2 = [cleaned_processed_timestamps[0]]\n",
    "\n",
    "        for i in range(1, len(cleaned_processed_timestamps)):\n",
    "            if (cleaned_processed_timestamps[i]['end']- cleaned_processed_timestamps[i]['start']) + (cleaned_processed_timestamps_2[-1]['end'] - cleaned_processed_timestamps_2[-1]['start']) < 29:\n",
    "                cleaned_processed_timestamps_2[-1]['end'] = cleaned_processed_timestamps[i]['end']\n",
    "            else:\n",
    "                cleaned_processed_timestamps_2.append(cleaned_processed_timestamps[i])\n",
    "\n",
    "        # Convert processed timestamps into audio segments\n",
    "        audio_segments = []\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        for j, cleaned_processed_timestamp in enumerate(cleaned_processed_timestamps):\n",
    "            start_ms = cleaned_processed_timestamp['start'] * 1000  # Convert seconds to milliseconds\n",
    "            end_ms = cleaned_processed_timestamp['end'] * 1000    # Convert seconds to milliseconds\n",
    "            segment = audio[start_ms:end_ms]\n",
    "\n",
    "            buffer = BytesIO()\n",
    "            segment.export(buffer, format=\"wav\")\n",
    "            saving_file_name = f\"./data/audio_chunks/{audio_id}-{j+1}.wav\"\n",
    "            segment.export(saving_file_name, format=\"wav\") # TODO: Try changing it to wav and observe the results\n",
    "            buffer.seek(0)  # Reset buffer pointer\n",
    "            audio_segments.append(buffer)\n",
    "\n",
    "        return audio_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from silero_vad import load_silero_vad, read_audio, get_speech_timestamps\n",
    "# from pydub import AudioSegment\n",
    "# from pydub.utils import mediainfo\n",
    "\n",
    "# import math\n",
    "# from io import BytesIO\n",
    "# from typing import IO, List\n",
    "\n",
    "# vad_model = load_silero_vad()\n",
    "\n",
    "# def _split_audio(audio_file):\n",
    "#     # 1. Read audio and prepare it for processing\n",
    "#     audio_bytes = audio_file.getvalue()\n",
    "\n",
    "#     # 2. Convert the audio into BytesIO object\n",
    "#     audio = BytesIO(audio_bytes)\n",
    "\n",
    "#     # 3. Read audio with it's sampling rate\n",
    "#     wav = read_audio(audio, sampling_rate=8000)\n",
    "\n",
    "#     # 4. Get speech timestamps from the vad model \n",
    "#     speech_timestamps = get_speech_timestamps(\n",
    "#         wav, \n",
    "#         vad_model, \n",
    "#         sampling_rate=8000, \n",
    "#         return_seconds=True\n",
    "#     )\n",
    "\n",
    "#     for speech_timestamp in speech_timestamps:\n",
    "#         duration = speech_timestamp['end'] - speech_timestamp['start']\n",
    "#         print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUDIO_FILE_PATH = \"./data/audio_recordings/1d70dc3e-73e6-419e-8270-a323efdbeb3f.mp3\"\n",
    "\n",
    "# with open(AUDIO_FILE_PATH, \"rb\") as f:\n",
    "#     audio_f = f.read()\n",
    "\n",
    "# audio_f = BytesIO(audio_f)\n",
    "\n",
    "# _split_audio(audio_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "vad_model = load_silero_vad()\n",
    "\n",
    "for root, _, files in os.walk(\"./data/audio_recordings/\"):\n",
    "    for file in files:\n",
    "        audio_file_path = os.path.join(root, file)\n",
    "\n",
    "        with open(audio_file_path, \"rb\") as f:\n",
    "            audio = f.read()\n",
    "\n",
    "        audio_id = audio_file_path.split(\"/\")[-1][:-4]\n",
    "        audio = BytesIO(audio)\n",
    "\n",
    "        audio_segments = _split_audio(audio, vad_model, 8000, audio_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio duration: 6 hours, 44 minutes, 9 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "# Specify the directory containing the audio files\n",
    "folder_path = \"./data/audio_chunks\"\n",
    "\n",
    "# Function to calculate the total audio duration in seconds\n",
    "def get_total_audio_duration(folder_path):\n",
    "    total_duration = 0\n",
    "\n",
    "    # Iterate through files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check if it's an audio file (you can extend this with more audio formats)\n",
    "        if filename.endswith(('.mp3', '.wav', '.flac', '.ogg', '.m4a')):  \n",
    "            try:\n",
    "                # Get audio duration info\n",
    "                audio_info = mediainfo(file_path)\n",
    "                duration = float(audio_info['duration'])\n",
    "                total_duration += duration\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process {filename}: {e}\")\n",
    "    \n",
    "    return total_duration\n",
    "\n",
    "# Call the function\n",
    "total_duration_seconds = get_total_audio_duration(folder_path)\n",
    "\n",
    "# Convert seconds to hours, minutes, and seconds\n",
    "hours = total_duration_seconds // 3600\n",
    "minutes = (total_duration_seconds % 3600) // 60\n",
    "seconds = total_duration_seconds % 60\n",
    "\n",
    "print(f\"Total audio duration: {int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telelyzer-transcript-feedback-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
